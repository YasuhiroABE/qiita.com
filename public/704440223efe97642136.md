---
title: Rook/Cephの/metricsにアクセスし、Prometheusで監視してみた
tags:
  - Ceph
  - kubernetes
  - Rook
private: false
updated_at: '2019-12-27T09:58:51+09:00'
id: 704440223efe97642136
organization_url_name: null
slide: false
ignorePublish: false
---
# はじめに

自前のKubernetes(K8s)クラスターでRook/Cephを利用していますが、K8sクラスターの外にPrometheusを導入しています。Rookの公式ドキュメントでは、metricsを取得する方法が記載されていますが、coreos/prometheus-operatorを前提にした設定になっているので、簡単なメモを残すことにしました。


# Rook/CephのServiceを調べてみる

```bash:kubectlコマンドでrook/cephのservice定義を確認する
$ kubectl -n rook-ceph get svc
NAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE
rook-ceph-mgr             ClusterIP   10.233.12.211   <none>        9283/TCP            214d
rook-ceph-mon-ah          ClusterIP   10.233.1.1      <none>        6789/TCP,3300/TCP   36d
rook-ceph-mon-ak          ClusterIP   10.233.27.34    <none>        6789/TCP,3300/TCP   6d20h
rook-ceph-mon-al          ClusterIP   10.233.25.114   <none>        6789/TCP,3300/TCP   6d20h
```

先頭のrook-ceph-mgrの/metricsにアクセスしてみます。

```bash:curlで/metricsを取得した結果
$ curl http://10.233.12.211:9283/metrics | grep -v '#' | head

ceph_mds_mem_dir_minus{ceph_daemon="mds.myfs-b"} 0.0
ceph_mds_mem_dir_minus{ceph_daemon="mds.myfs-a"} 43227.0
ceph_paxos_store_state_latency_sum{ceph_daemon="mon.ak"} 13650.276728195
ceph_paxos_store_state_latency_sum{ceph_daemon="mon.al"} 11494.469300331
ceph_paxos_store_state_latency_sum{ceph_daemon="mon.ah"} 30.680001772
ceph_mds_cache_recovery_completed{ceph_daemon="mds.myfs-b"} 0.0
ceph_mds_cache_recovery_completed{ceph_daemon="mds.myfs-a"} 0.0
ceph_osd_op_out_bytes{ceph_daemon="osd.3"} 1192672815.0
ceph_osd_op_out_bytes{ceph_daemon="osd.1"} 893430742.0
```

あとは、この/metricsをどうやって取得するかを検討します。

# 方法1: Rook/Cephのmetricsを外部にexportする

既存のrook-ceph-mgr定義を参考にして、80番ポートで稼動させてみたりします。

```bash
$ kubectl -n rook-ceph get svc rook-ceph-mgr -o yaml > metrics.service.yaml
$ vi metrics.service.yaml
$ kubectl -n rook-ceph apply -f metrics.service.yaml
```

viでは不要な.metadataの要素や.statusなどを削除しています。

```yaml
apiVersion: v1
kind: Service
metadata:
  name: rook-ceph-metrics
  namespace: rook-ceph
spec:
  ports:
  - name: http-metrics
    port: 80
    protocol: TCP
    targetPort: 9283
  selector:
    app: rook-ceph-mgr
    rook_cluster: rook-ceph
  type: LoadBalancer
  loadBalancerIP: 192.168.1.46
```

# 方法2: rook-ceph-mgr/metricsにproxyするIngressを利用する

方法については省略。

# まとめ

前提として、K8sが稼動するネットワークは外部から切り離されていて、外部に公開するサービスは別にnginxを境界に立ち上げて管理している点と、rook-ceph-mgrの9283ポートはPrometheus用なので、そのままLoadBalancerに登録して公開しています。

/metricsが他のサービスと同じIP:Portで公開されている場合には、セキュリティ上の懸念がないか慎重に考慮するべきかなとは思いました。（この場合には限られたpathをexportするようingressを利用すると思います）

Grafana Labsには、Ceph用のJSONが登録されているので、これをDashboardにして様子をみています。

* https://grafana.com/grafana/dashboards/7056

見た目も大事ですが、この定義を確認すると、alert_rules.yamlに追加するべき監視項目が分かるので、公開されているDashboardの定義情報は監視項目の設定の参考になると思います。

以上
